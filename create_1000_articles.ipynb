{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11de3e50",
   "metadata": {},
   "source": [
    "# Create a thousand articles for one topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d11fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U google-genai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88fb253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2070d6d2",
   "metadata": {},
   "source": [
    "# Make sure you create a .env.local file and put your GEMINI_API_KEY in there.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a24db55",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\".env.local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5131d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "# The client gets the API key from the environment variable `GEMINI_API_KEY`.\n",
    "client = genai.Client(api_key=gemini_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d85715",
   "metadata": {},
   "source": [
    "# Generate topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69629c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"prompts/topic_generation.txt\", \"r\") as f:\n",
    "    topic_prompt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a994bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\", contents=topic_prompt,\n",
    ")\n",
    "topics = response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e57cce",
   "metadata": {},
   "source": [
    "# Save the list of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66caa738",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_list = json.loads(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60ceb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"articles/machine_learning/list_of_topics.json\", \"w\") as f:\n",
    "    json.dump(json.loads(topics), f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08cb12d",
   "metadata": {},
   "source": [
    "# Generate Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4fe545",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"prompts/article_creation.text\", \"r\") as f:\n",
    "    prompt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b872aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_article(topic, article, idx):\n",
    "    # lowecase all topics, split by space, and join with underscore\n",
    "    # example: \"Machine Learning\" -> \"machine_learning\"\n",
    "    title = \"_\".join(topic.lower().split(\" \"))\n",
    "    with open(f\"articles/machine_learning/{title}.json\", \"w\") as f:\n",
    "        json.dump(article, f, indent=2)\n",
    "    print(f\"Saved article {idx + 1} for topic: {title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b470ed3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A while loop to generate articles for each topic is bettern than a for loop\n",
    "# because the LLM can generate non-json responses, and we can handle that case\n",
    "is_done = False\n",
    "index = 0\n",
    "# This could be long. Reduce the number of topics to generate articles for and do it in batches.\n",
    "shortened_topics = topics_list[0:5]  # Adjust the range as needed\n",
    "total = len(shortened_topics)  # Adjust the range as needed\n",
    "pbar = tqdm(total=total)\n",
    "while not is_done:\n",
    "    topic = shortened_topics[index]\n",
    "    final_prompt = prompt.format(topic=topic)\n",
    "    print(f\"Generating article for topic: {topic}\")\n",
    "    article_response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\", contents=final_prompt,\n",
    "    )\n",
    "    article_text = article_response.text\n",
    "    try:\n",
    "        article_dict = json.loads(article_text)\n",
    "        save_article(shortened_topics[index], article_dict, index)\n",
    "        index += 1\n",
    "        pbar.update(total - pbar.n)\n",
    "    except json.JSONDecodeError:\n",
    "        # two options now.\n",
    "        # 1. The response is not a valid JSON, we can try to fix it.\n",
    "        print(\"Response is not a valid JSON, trying to fix it.\")\n",
    "        if '```json' in article_text:\n",
    "            # remove the ````json` and ` ``` ` from the response\n",
    "            # clean_text = article_text.split('```json')[1].split('```')[0].strip()\n",
    "            # this is better because the LLM could generate ```json in the middle of the response`\n",
    "            clean_text = article_text[8:-4].strip()\n",
    "            try:\n",
    "                article_dict = json.loads(clean_text)\n",
    "                save_article(shortened_topics[index], article_dict, index)\n",
    "                index += 1\n",
    "                pbar.update(total - pbar.n)\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"Still not a valid JSON, redo generation.\")\n",
    "                # If it still fails, we can just skip this topic and move to the next one.\n",
    "        else:\n",
    "            print(\"Response is not a valid JSON, redo generation.\")\n",
    "        # 2. The response is not a valid JSON, we can reset and have it generate again.\n",
    "    if index >= len(shortened_topics):\n",
    "        is_done = True\n",
    "pbar.update(total - pbar.n)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f8b99e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
